{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://shubham-shinde.github.io/blogs/arcface/ - spoko wyja≈õnienie czym jest ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa\n",
    "# !pip install focal-loss\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from focal_loss import BinaryFocalLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# glowny folder\n",
    "base_dir = '/Users/milenabiernacka/Desktop/studia/DS/semestr2/PD-magisterka/Mushroom_dataset/cnn/'\n",
    "# polaczenie glownego folderu i podfolderow z edible i poisonous\n",
    "\n",
    "edible_dir = os.path.join(base_dir, 'Edible')\n",
    "poisonous_dir = os.path.join(base_dir, 'Poisonous')\n",
    "\n",
    "# Assuming base_dir is the path to the dataset directory\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_generator(generator):\n",
    "    for batch_x, batch_y in generator:\n",
    "        yield [batch_x, batch_y], batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_wrapper = wrapper_generator(train_generator)\n",
    "validation_gen_wrapper = wrapper_generator(validation_generator)\n",
    "test_gen_wrapper = wrapper_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object wrapper_generator at 0x344073a00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFaceLossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_classes=2, s=30.0, m=0.50, **kwargs):\n",
    "        super(ArcFaceLossLayer, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s  # Scale parameter\n",
    "        self.m = m  # Margin parameter\n",
    "        self.cos_m = tf.cos(m)\n",
    "        self.sin_m = tf.sin(m)\n",
    "        self.th = tf.cos(tf.constant(np.pi) - m)\n",
    "        self.mm = tf.sin(tf.constant(np.pi) - m) * m\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(input_shape[-1], self.n_classes),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True,\n",
    "                                 dtype='float32')\n",
    "\n",
    "    def call(self, inputs, labels):\n",
    "        # Normalize feature vectors and weights\n",
    "        x = tf.nn.l2_normalize(inputs, axis=1)\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # Dot product\n",
    "        logits = x @ W\n",
    "        # Add margin\n",
    "        theta = tf.acos(tf.clip_by_value(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
    "        target_logits = tf.cos(theta + self.m)\n",
    "        logits = logits * (1 - labels) + target_logits * labels\n",
    "        # Rescale logits\n",
    "        return logits * self.s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_arcface_loss(input_shape=(150, 150, 3), n_classes=2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # No activation on the last dense layer\n",
    "    x = Dense(128)(x)  # This is the embedding layer\n",
    "    # Note: ArcFace layer is typically applied during training only\n",
    "\n",
    "    # Placeholder for labels\n",
    "    labels = Input(shape=(n_classes,))\n",
    "    # Instantiate ArcFace loss layer\n",
    "    arcface_loss = ArcFaceLossLayer(n_classes=n_classes)(x, labels)\n",
    "\n",
    "    model = Model(inputs=[inputs, labels], outputs=arcface_loss)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_with_arcface_loss(input_shape=(150, 150, 3), n_classes=2)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss=[tf.nn.softmax_cross_entropy_with_logits],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# When fitting the model, ensure to pass both the images and labels as input,\n",
    "# and similarly for validation. You might need to adjust your data generator\n",
    "# or data loading mechanism to achieve this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 11s 254ms/step - loss: 6.4426 - accuracy: 0.5022 - val_loss: 5.1759 - val_accuracy: 0.7361\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 11s 248ms/step - loss: 5.3858 - accuracy: 0.5260 - val_loss: 4.5934 - val_accuracy: 0.7313\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 11s 252ms/step - loss: 4.7664 - accuracy: 0.5523 - val_loss: 3.6961 - val_accuracy: 0.6940\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 11s 258ms/step - loss: 3.4335 - accuracy: 0.6042 - val_loss: 2.7667 - val_accuracy: 0.7015\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 12s 271ms/step - loss: 2.5074 - accuracy: 0.6964 - val_loss: 2.0815 - val_accuracy: 0.7687\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 11s 262ms/step - loss: 1.7464 - accuracy: 0.7740 - val_loss: 2.1203 - val_accuracy: 0.7873\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 11s 265ms/step - loss: 1.4317 - accuracy: 0.8149 - val_loss: 1.4718 - val_accuracy: 0.8507\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 1.0032 - accuracy: 0.8500 - val_loss: 1.6205 - val_accuracy: 0.8134\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 13s 303ms/step - loss: 0.7783 - accuracy: 0.8895 - val_loss: 2.0325 - val_accuracy: 0.8246\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 14s 317ms/step - loss: 0.7666 - accuracy: 0.8888 - val_loss: 1.5001 - val_accuracy: 0.8246\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 13s 301ms/step - loss: 0.6170 - accuracy: 0.8954 - val_loss: 1.5861 - val_accuracy: 0.8681\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 12s 284ms/step - loss: 0.3927 - accuracy: 0.9378 - val_loss: 1.5525 - val_accuracy: 0.8507\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 12s 283ms/step - loss: 0.3038 - accuracy: 0.9481 - val_loss: 1.4338 - val_accuracy: 0.8545\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 12s 280ms/step - loss: 0.2022 - accuracy: 0.9627 - val_loss: 1.6129 - val_accuracy: 0.8881\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 12s 277ms/step - loss: 0.1826 - accuracy: 0.9612 - val_loss: 1.5415 - val_accuracy: 0.8881\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 0.0850 - accuracy: 0.9795 - val_loss: 1.3947 - val_accuracy: 0.8918\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 0.0906 - accuracy: 0.9817 - val_loss: 1.6252 - val_accuracy: 0.8955\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 14s 318ms/step - loss: 0.0414 - accuracy: 0.9898 - val_loss: 1.2215 - val_accuracy: 0.8955\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 13s 293ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 2.0548 - val_accuracy: 0.8881\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 1.5779 - val_accuracy: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3564e9e90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_gen_wrapper,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_gen_wrapper,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 75ms/step - loss: 1.4404 - accuracy: 0.8819\n",
      "Test Loss: 1.440354585647583, Test Accuracy: 0.8819444179534912\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_gen_wrapper, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magisterka",
   "language": "python",
   "name": "magisterka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
