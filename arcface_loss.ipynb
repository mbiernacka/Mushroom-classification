{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://shubham-shinde.github.io/blogs/arcface/ - spoko wyjaśnienie czym jest ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Lambda, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa\n",
    "# !pip install focal-loss\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from focal_loss import BinaryFocalLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# glowny folder\n",
    "base_dir = '/Users/milenabiernacka/Desktop/studia/DS/semestr2/PD-magisterka/Mushroom_dataset/cnn/'\n",
    "# polaczenie glownego folderu i podfolderow z edible i poisonous\n",
    "\n",
    "edible_dir = os.path.join(base_dir, 'Edible')\n",
    "poisonous_dir = os.path.join(base_dir, 'Poisonous')\n",
    "\n",
    "# Assuming base_dir is the path to the dataset directory\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_generator(generator):\n",
    "    for batch_x, batch_y in generator:\n",
    "        yield [batch_x, batch_y], batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_wrapper = wrapper_generator(train_generator)\n",
    "validation_gen_wrapper = wrapper_generator(validation_generator)\n",
    "test_gen_wrapper = wrapper_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object wrapper_generator at 0x310e92880>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFaceLossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_classes=2, s=30.0, m=0.50, **kwargs):\n",
    "        super(ArcFaceLossLayer, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s  # Scale parameter\n",
    "        self.m = m  # Margin parameter\n",
    "        self.cos_m = tf.cos(m)\n",
    "        self.sin_m = tf.sin(m)\n",
    "        self.th = tf.cos(tf.constant(np.pi) - m)\n",
    "        self.mm = tf.sin(tf.constant(np.pi) - m) * m\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(input_shape[-1], self.n_classes),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True,\n",
    "                                 dtype='float32')\n",
    "\n",
    "    def call(self, inputs, labels):\n",
    "        # Normalize feature vectors and weights\n",
    "        x = tf.nn.l2_normalize(inputs, axis=1)\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # Dot product\n",
    "        logits = x @ W\n",
    "        # Add margin\n",
    "        theta = tf.acos(tf.clip_by_value(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
    "        target_logits = tf.cos(theta + self.m)\n",
    "        logits = logits * (1 - labels) + target_logits * labels\n",
    "        # Rescale logits\n",
    "        return logits * self.s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_arcface_loss(input_shape=(150, 150, 3), n_classes=2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # No activation on the last dense layer\n",
    "    x = Dense(128)(x)  # This is the embedding layer\n",
    "    # Note: ArcFace layer is typically applied during training only\n",
    "\n",
    "    # Placeholder for labels\n",
    "    labels = Input(shape=(n_classes,))\n",
    "    # Instantiate ArcFace loss layer\n",
    "    arcface_loss = ArcFaceLossLayer(n_classes=n_classes)(x, labels)\n",
    "\n",
    "    model = Model(inputs=[inputs, labels], outputs=arcface_loss)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_with_arcface_loss(input_shape=(150, 150, 3), n_classes=2)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss=[tf.nn.softmax_cross_entropy_with_logits],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# When fitting the model, ensure to pass both the images and labels as input,\n",
    "# and similarly for validation. You might need to adjust your data generator\n",
    "# or data loading mechanism to achieve this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 11s 254ms/step - loss: 6.4426 - accuracy: 0.5022 - val_loss: 5.1759 - val_accuracy: 0.7361\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 11s 248ms/step - loss: 5.3858 - accuracy: 0.5260 - val_loss: 4.5934 - val_accuracy: 0.7313\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 11s 252ms/step - loss: 4.7664 - accuracy: 0.5523 - val_loss: 3.6961 - val_accuracy: 0.6940\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 11s 258ms/step - loss: 3.4335 - accuracy: 0.6042 - val_loss: 2.7667 - val_accuracy: 0.7015\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 12s 271ms/step - loss: 2.5074 - accuracy: 0.6964 - val_loss: 2.0815 - val_accuracy: 0.7687\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 11s 262ms/step - loss: 1.7464 - accuracy: 0.7740 - val_loss: 2.1203 - val_accuracy: 0.7873\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 11s 265ms/step - loss: 1.4317 - accuracy: 0.8149 - val_loss: 1.4718 - val_accuracy: 0.8507\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 1.0032 - accuracy: 0.8500 - val_loss: 1.6205 - val_accuracy: 0.8134\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 13s 303ms/step - loss: 0.7783 - accuracy: 0.8895 - val_loss: 2.0325 - val_accuracy: 0.8246\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 14s 317ms/step - loss: 0.7666 - accuracy: 0.8888 - val_loss: 1.5001 - val_accuracy: 0.8246\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 13s 301ms/step - loss: 0.6170 - accuracy: 0.8954 - val_loss: 1.5861 - val_accuracy: 0.8681\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 12s 284ms/step - loss: 0.3927 - accuracy: 0.9378 - val_loss: 1.5525 - val_accuracy: 0.8507\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 12s 283ms/step - loss: 0.3038 - accuracy: 0.9481 - val_loss: 1.4338 - val_accuracy: 0.8545\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 12s 280ms/step - loss: 0.2022 - accuracy: 0.9627 - val_loss: 1.6129 - val_accuracy: 0.8881\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 12s 277ms/step - loss: 0.1826 - accuracy: 0.9612 - val_loss: 1.5415 - val_accuracy: 0.8881\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 0.0850 - accuracy: 0.9795 - val_loss: 1.3947 - val_accuracy: 0.8918\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 0.0906 - accuracy: 0.9817 - val_loss: 1.6252 - val_accuracy: 0.8955\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 14s 318ms/step - loss: 0.0414 - accuracy: 0.9898 - val_loss: 1.2215 - val_accuracy: 0.8955\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 13s 293ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 2.0548 - val_accuracy: 0.8881\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 1.5779 - val_accuracy: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3564e9e90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_gen_wrapper,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_gen_wrapper,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 75ms/step - loss: 1.4404 - accuracy: 0.8819\n",
      "Test Loss: 1.440354585647583, Test Accuracy: 0.8819444179534912\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_gen_wrapper, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrenowane sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43/43 [==============================] - 5s 104ms/step - loss: 7.9426 - accuracy: 0.4733 - val_loss: 5.5918 - val_accuracy: 0.7188\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 5.0160 - accuracy: 0.5040 - val_loss: 3.0223 - val_accuracy: 0.6940\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 2.9998 - accuracy: 0.5413 - val_loss: 1.2799 - val_accuracy: 0.8097\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 4s 99ms/step - loss: 1.6429 - accuracy: 0.7593 - val_loss: 0.8794 - val_accuracy: 0.8433\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 4s 100ms/step - loss: 0.9842 - accuracy: 0.8361 - val_loss: 0.6004 - val_accuracy: 0.9030\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 4s 100ms/step - loss: 0.7500 - accuracy: 0.8830 - val_loss: 0.4214 - val_accuracy: 0.9403\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 0.5701 - accuracy: 0.9166 - val_loss: 0.4276 - val_accuracy: 0.9291\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.4439 - accuracy: 0.9349 - val_loss: 0.3504 - val_accuracy: 0.9403\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.3401 - accuracy: 0.9378 - val_loss: 0.5490 - val_accuracy: 0.9328\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.2274 - accuracy: 0.9612 - val_loss: 0.2314 - val_accuracy: 0.9664\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 4s 101ms/step - loss: 0.2116 - accuracy: 0.9576 - val_loss: 0.3213 - val_accuracy: 0.9722\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 4s 104ms/step - loss: 0.1723 - accuracy: 0.9678 - val_loss: 0.2818 - val_accuracy: 0.9739\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0990 - accuracy: 0.9744 - val_loss: 0.1461 - val_accuracy: 0.9888\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0939 - accuracy: 0.9824 - val_loss: 0.0141 - val_accuracy: 0.9963\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 5s 107ms/step - loss: 0.0608 - accuracy: 0.9846 - val_loss: 0.1101 - val_accuracy: 0.9851\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 5s 108ms/step - loss: 0.0417 - accuracy: 0.9883 - val_loss: 0.2300 - val_accuracy: 0.9813\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.2303 - val_accuracy: 0.9739\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.3530 - val_accuracy: 0.9776\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 5s 108ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.1518 - val_accuracy: 0.9813\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 5s 108ms/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.3337 - val_accuracy: 0.9776\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.3449 - val_accuracy: 0.9688\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.0476 - accuracy: 0.9854 - val_loss: 0.1034 - val_accuracy: 0.9888\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.2806 - val_accuracy: 0.9776\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.0299 - accuracy: 0.9949 - val_loss: 0.3171 - val_accuracy: 0.9851\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.2672 - val_accuracy: 0.9776\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.2348 - val_accuracy: 0.9813\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.4677 - val_accuracy: 0.9739\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.0059 - accuracy: 0.9971 - val_loss: 0.1497 - val_accuracy: 0.9851\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.2174 - val_accuracy: 0.9851\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.2297 - val_accuracy: 0.9851\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.1386 - val_accuracy: 0.9896\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.2581 - val_accuracy: 0.9776\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 3.2205e-04 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9851\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 0.4281 - val_accuracy: 0.9664\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0052 - accuracy: 0.9978 - val_loss: 0.0672 - val_accuracy: 0.9925\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.0867 - val_accuracy: 0.9925\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9739\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.1717 - val_accuracy: 0.9851\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0222 - accuracy: 0.9956 - val_loss: 0.2990 - val_accuracy: 0.9813\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1113 - val_accuracy: 0.9888\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.2695 - val_accuracy: 0.9826\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2607 - val_accuracy: 0.9813\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9813\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.2739 - val_accuracy: 0.9813\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.2166 - val_accuracy: 0.9851\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 1.0345e-04 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9813\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 9.8833e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9813\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - 6s 129ms/step - loss: 0.0029 - accuracy: 0.9978 - val_loss: 0.2147 - val_accuracy: 0.9851\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 3.5854e-04 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9851\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.2045 - val_accuracy: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x314080510>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Funkcja do budowania modelu z MobileNetV2 i warstwą ArcFace\n",
    "def build_model_with_arcface_loss(input_shape=(128, 128, 3), n_classes=2):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    # Zamrożenie warstw modelu bazowego\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    labels = Input(shape=(n_classes,))\n",
    "    \n",
    "    x = base_model(inputs)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128)(x)  # Warstwa embeddingu\n",
    "    \n",
    "    # Dodanie warstwy ArcFaceLossLayer\n",
    "    arcface_loss = ArcFaceLossLayer(n_classes=n_classes)(x, labels)\n",
    "    \n",
    "    model = Model(inputs=[inputs, labels], outputs=arcface_loss)\n",
    "    return model\n",
    "\n",
    "model = build_model_with_arcface_loss(input_shape=(128, 128, 3), n_classes=2)\n",
    "\n",
    "\n",
    "# Kompilacja modelu z niestandardową funkcją straty i optymalizatorem\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=[tf.nn.softmax_cross_entropy_with_logits], metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_gen_wrapper,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_gen_wrapper,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3223 - accuracy: 0.9665\n",
      "Test Loss: 0.3222656846046448, Test Accuracy: 0.9665427803993225\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_gen_wrapper, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magisterka",
   "language": "python",
   "name": "magisterka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
