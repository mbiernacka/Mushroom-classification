{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install focal-loss\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, Input, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystany zbiór: https://zenodo.org/records/6378474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# glowny folder\n",
    "base_dir = '/Users/milenabiernacka/Desktop/studia/DS/semestr2/PD-magisterka/Mushroom_dataset/cnn/'\n",
    "# polaczenie glownego folderu i podfolderow z edible i poisonous\n",
    "\n",
    "edible_dir = os.path.join(base_dir, 'Edible')\n",
    "poisonous_dir = os.path.join(base_dir, 'Poisonous')\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Assuming base_dir is the path to the dataset directory\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=1,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(150, 150, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Use linear activation for Hinge loss\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seesaw_loss_with_penalty(y_true, y_pred, penalty=0.5):\n",
    "    \"\"\"\n",
    "    A simplified conceptual version of seesaw loss for binary classification.\n",
    "    This function penalizes the loss for the majority class and reduces the penalty\n",
    "    for the minority class, attempting to balance the seesaw between classes.\n",
    "\n",
    "    Args:\n",
    "    - y_true: True labels.\n",
    "    - y_pred: Predicted labels.\n",
    "    - penalty: The penalty factor for the majority class. Lower values reduce the loss\n",
    "               contribution from the majority class.\n",
    "\n",
    "    Returns:\n",
    "    - A modified binary cross-entropy loss that incorporates class balancing.\n",
    "    \"\"\"\n",
    "    # Standard binary cross-entropy\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    # Determine weights for each sample based on its true label\n",
    "    weights = K.abs(y_true - penalty)  # Reduce weight for majority class (assumed to be 1)\n",
    "\n",
    "    # Apply seesaw penalty\n",
    "    weighted_bce = weights * bce\n",
    "\n",
    "    return K.mean(weighted_bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=lambda y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty=0.8), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1399/1399 [==============================] - 57s 40ms/step - loss: 0.1770 - accuracy: 0.7362 - val_loss: 0.1479 - val_accuracy: 0.7326\n",
      "Epoch 2/20\n",
      "1399/1399 [==============================] - 53s 38ms/step - loss: 0.1392 - accuracy: 0.7412 - val_loss: 0.1297 - val_accuracy: 0.7431\n",
      "Epoch 3/20\n",
      "1399/1399 [==============================] - 57s 40ms/step - loss: 0.1188 - accuracy: 0.7777 - val_loss: 0.1182 - val_accuracy: 0.7569\n",
      "Epoch 4/20\n",
      "1399/1399 [==============================] - 60s 43ms/step - loss: 0.0982 - accuracy: 0.8392 - val_loss: 0.0760 - val_accuracy: 0.9132\n",
      "Epoch 5/20\n",
      "1399/1399 [==============================] - 58s 41ms/step - loss: 0.0831 - accuracy: 0.8721 - val_loss: 0.0654 - val_accuracy: 0.8993\n",
      "Epoch 6/20\n",
      "1399/1399 [==============================] - 59s 42ms/step - loss: 0.0696 - accuracy: 0.9021 - val_loss: 0.0557 - val_accuracy: 0.9306\n",
      "Epoch 7/20\n",
      "1399/1399 [==============================] - 61s 43ms/step - loss: 0.0637 - accuracy: 0.9056 - val_loss: 0.0447 - val_accuracy: 0.9410\n",
      "Epoch 8/20\n",
      "1399/1399 [==============================] - 60s 43ms/step - loss: 0.0564 - accuracy: 0.9157 - val_loss: 0.0718 - val_accuracy: 0.9479\n",
      "Epoch 9/20\n",
      "1399/1399 [==============================] - 60s 43ms/step - loss: 0.0488 - accuracy: 0.9271 - val_loss: 0.0321 - val_accuracy: 0.9514\n",
      "Epoch 10/20\n",
      "1399/1399 [==============================] - 60s 43ms/step - loss: 0.0404 - accuracy: 0.9450 - val_loss: 0.1228 - val_accuracy: 0.9306\n",
      "Epoch 11/20\n",
      "1399/1399 [==============================] - 59s 42ms/step - loss: 0.0318 - accuracy: 0.9550 - val_loss: 0.0259 - val_accuracy: 0.9757\n",
      "Epoch 12/20\n",
      "1399/1399 [==============================] - 58s 42ms/step - loss: 0.0345 - accuracy: 0.9578 - val_loss: 0.0397 - val_accuracy: 0.9375\n",
      "Epoch 13/20\n",
      "1399/1399 [==============================] - 59s 42ms/step - loss: 0.0314 - accuracy: 0.9607 - val_loss: 0.0179 - val_accuracy: 0.9653\n",
      "Epoch 14/20\n",
      "1399/1399 [==============================] - 61s 43ms/step - loss: 0.0276 - accuracy: 0.9721 - val_loss: 0.0208 - val_accuracy: 0.9583\n",
      "Epoch 15/20\n",
      "1399/1399 [==============================] - 61s 43ms/step - loss: 0.0240 - accuracy: 0.9671 - val_loss: 0.0386 - val_accuracy: 0.9514\n",
      "Epoch 16/20\n",
      "1399/1399 [==============================] - 61s 44ms/step - loss: 0.0201 - accuracy: 0.9685 - val_loss: 0.0435 - val_accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "1399/1399 [==============================] - 62s 44ms/step - loss: 0.0172 - accuracy: 0.9764 - val_loss: 0.0254 - val_accuracy: 0.9583\n",
      "Epoch 18/20\n",
      "1399/1399 [==============================] - 61s 43ms/step - loss: 0.0204 - accuracy: 0.9700 - val_loss: 0.1676 - val_accuracy: 0.9167\n",
      "Epoch 19/20\n",
      "1399/1399 [==============================] - 59s 43ms/step - loss: 0.0252 - accuracy: 0.9707 - val_loss: 0.0138 - val_accuracy: 0.9826\n",
      "Epoch 20/20\n",
      "1399/1399 [==============================] - 64s 46ms/step - loss: 0.0105 - accuracy: 0.9878 - val_loss: 0.0199 - val_accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 127s 16s/step - loss: 0.0198 - accuracy: 0.9792\n",
      "Test Loss: 0.01980467326939106, Test Accuracy: 0.9791666865348816\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=Adam(learning_rate=1e-4), loss=lambda y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty=0.5), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "#     epochs=20,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "# print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=1,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1399/1399 [==============================] - 16s 11ms/step - loss: 0.0704 - accuracy: 0.9235 - val_loss: 0.0372 - val_accuracy: 0.9757\n",
      "Epoch 2/50\n",
      "1399/1399 [==============================] - 16s 12ms/step - loss: 0.0311 - accuracy: 0.9721 - val_loss: 0.0240 - val_accuracy: 0.9722\n",
      "Epoch 3/50\n",
      "1399/1399 [==============================] - 16s 11ms/step - loss: 0.0226 - accuracy: 0.9807 - val_loss: 0.0092 - val_accuracy: 0.9965\n",
      "Epoch 4/50\n",
      "1399/1399 [==============================] - 17s 12ms/step - loss: 0.0094 - accuracy: 0.9950 - val_loss: 0.0117 - val_accuracy: 0.9861\n",
      "Epoch 5/50\n",
      "1399/1399 [==============================] - 18s 13ms/step - loss: 0.0169 - accuracy: 0.9843 - val_loss: 0.0139 - val_accuracy: 0.9861\n",
      "Epoch 6/50\n",
      "1399/1399 [==============================] - 19s 13ms/step - loss: 0.0137 - accuracy: 0.9900 - val_loss: 0.0278 - val_accuracy: 0.9722\n",
      "Epoch 7/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0121 - accuracy: 0.9921 - val_loss: 0.0224 - val_accuracy: 0.9826\n",
      "Epoch 8/50\n",
      "1399/1399 [==============================] - 21s 15ms/step - loss: 0.0104 - accuracy: 0.9907 - val_loss: 0.0080 - val_accuracy: 0.9965\n",
      "Epoch 9/50\n",
      "1399/1399 [==============================] - 21s 15ms/step - loss: 0.0142 - accuracy: 0.9900 - val_loss: 0.0152 - val_accuracy: 0.9931\n",
      "Epoch 10/50\n",
      "1399/1399 [==============================] - 21s 15ms/step - loss: 0.0066 - accuracy: 0.9950 - val_loss: 0.0065 - val_accuracy: 0.9896\n",
      "Epoch 11/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0069 - accuracy: 0.9921 - val_loss: 0.0149 - val_accuracy: 0.9861\n",
      "Epoch 12/50\n",
      "1399/1399 [==============================] - 18s 13ms/step - loss: 0.0157 - accuracy: 0.9857 - val_loss: 0.0430 - val_accuracy: 0.9722\n",
      "Epoch 13/50\n",
      "1399/1399 [==============================] - 19s 13ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 0.0178 - val_accuracy: 0.9861\n",
      "Epoch 14/50\n",
      "1399/1399 [==============================] - 19s 13ms/step - loss: 0.0055 - accuracy: 0.9950 - val_loss: 0.0155 - val_accuracy: 0.9826\n",
      "Epoch 15/50\n",
      "1399/1399 [==============================] - 19s 14ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.0132 - val_accuracy: 0.9931\n",
      "Epoch 16/50\n",
      "1399/1399 [==============================] - 19s 13ms/step - loss: 0.0063 - accuracy: 0.9950 - val_loss: 0.0409 - val_accuracy: 0.9757\n",
      "Epoch 17/50\n",
      "1399/1399 [==============================] - 18s 13ms/step - loss: 0.0056 - accuracy: 0.9957 - val_loss: 0.0113 - val_accuracy: 0.9931\n",
      "Epoch 18/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0086 - accuracy: 0.9943 - val_loss: 0.0329 - val_accuracy: 0.9826\n",
      "Epoch 19/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0047 - accuracy: 0.9971 - val_loss: 0.0132 - val_accuracy: 0.9931\n",
      "Epoch 20/50\n",
      "1399/1399 [==============================] - 18s 13ms/step - loss: 0.0034 - accuracy: 0.9971 - val_loss: 0.0135 - val_accuracy: 0.9861\n",
      "Epoch 21/50\n",
      "1399/1399 [==============================] - 18s 13ms/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 0.0099 - val_accuracy: 0.9896\n",
      "Epoch 22/50\n",
      "1399/1399 [==============================] - 19s 13ms/step - loss: 0.0067 - accuracy: 0.9950 - val_loss: 0.0096 - val_accuracy: 0.9965\n",
      "Epoch 23/50\n",
      "1399/1399 [==============================] - 19s 14ms/step - loss: 0.0130 - accuracy: 0.9921 - val_loss: 0.0089 - val_accuracy: 0.9965\n",
      "Epoch 24/50\n",
      "1399/1399 [==============================] - 19s 13ms/step - loss: 3.4287e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9965\n",
      "Epoch 25/50\n",
      "1399/1399 [==============================] - 19s 14ms/step - loss: 0.0037 - accuracy: 0.9964 - val_loss: 0.0225 - val_accuracy: 0.9896\n",
      "Epoch 26/50\n",
      "1399/1399 [==============================] - 19s 14ms/step - loss: 0.0049 - accuracy: 0.9950 - val_loss: 0.0049 - val_accuracy: 0.9965\n",
      "Epoch 27/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 1.8327e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9965\n",
      "Epoch 28/50\n",
      "1399/1399 [==============================] - 20s 15ms/step - loss: 0.0055 - accuracy: 0.9950 - val_loss: 0.0541 - val_accuracy: 0.9826\n",
      "Epoch 29/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0062 - accuracy: 0.9943 - val_loss: 0.0099 - val_accuracy: 0.9931\n",
      "Epoch 30/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 1.7268e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9896\n",
      "Epoch 31/50\n",
      "1399/1399 [==============================] - 21s 15ms/step - loss: 0.0064 - accuracy: 0.9943 - val_loss: 0.0107 - val_accuracy: 0.9931\n",
      "Epoch 32/50\n",
      "1399/1399 [==============================] - 21s 15ms/step - loss: 0.0022 - accuracy: 0.9979 - val_loss: 0.0045 - val_accuracy: 0.9931\n",
      "Epoch 33/50\n",
      "1399/1399 [==============================] - 21s 15ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0223 - val_accuracy: 0.9861\n",
      "Epoch 34/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0017 - accuracy: 0.9979 - val_loss: 0.0044 - val_accuracy: 0.9931\n",
      "Epoch 35/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0033 - accuracy: 0.9964 - val_loss: 0.0037 - val_accuracy: 0.9965\n",
      "Epoch 36/50\n",
      "1399/1399 [==============================] - 21s 15ms/step - loss: 0.0045 - accuracy: 0.9971 - val_loss: 0.0078 - val_accuracy: 0.9965\n",
      "Epoch 37/50\n",
      "1399/1399 [==============================] - 21s 15ms/step - loss: 2.5818e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9931\n",
      "Epoch 38/50\n",
      "1399/1399 [==============================] - 18s 13ms/step - loss: 0.0087 - accuracy: 0.9929 - val_loss: 0.0131 - val_accuracy: 0.9931\n",
      "Epoch 39/50\n",
      "1399/1399 [==============================] - 19s 14ms/step - loss: 0.0033 - accuracy: 0.9964 - val_loss: 0.0415 - val_accuracy: 0.9792\n",
      "Epoch 40/50\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0029 - accuracy: 0.9971 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1399/1399 [==============================] - 20s 15ms/step - loss: 0.0025 - accuracy: 0.9971 - val_loss: 0.0017 - val_accuracy: 0.9965\n",
      "Epoch 42/50\n",
      "1399/1399 [==============================] - 22s 16ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 0.0084 - val_accuracy: 0.9931\n",
      "Epoch 43/50\n",
      "1399/1399 [==============================] - 22s 16ms/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 0.0098 - val_accuracy: 0.9931\n",
      "Epoch 44/50\n",
      "1399/1399 [==============================] - 23s 16ms/step - loss: 0.0117 - accuracy: 0.9943 - val_loss: 0.0068 - val_accuracy: 0.9931\n",
      "Epoch 45/50\n",
      "1399/1399 [==============================] - 24s 17ms/step - loss: 5.9734e-04 - accuracy: 0.9993 - val_loss: 0.0032 - val_accuracy: 0.9965\n",
      "Epoch 46/50\n",
      "1399/1399 [==============================] - 23s 16ms/step - loss: 5.6516e-04 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9931\n",
      "Epoch 47/50\n",
      "1399/1399 [==============================] - 22s 16ms/step - loss: 0.0057 - accuracy: 0.9964 - val_loss: 0.0069 - val_accuracy: 0.9965\n",
      "Epoch 48/50\n",
      "1399/1399 [==============================] - 24s 17ms/step - loss: 0.0024 - accuracy: 0.9979 - val_loss: 0.0022 - val_accuracy: 0.9965\n",
      "Epoch 49/50\n",
      "1399/1399 [==============================] - 24s 17ms/step - loss: 3.2316e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9965\n",
      "Epoch 50/50\n",
      "1399/1399 [==============================] - 19s 14ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "# Wykorzystanie pretrenowanych sieci\n",
    "### MobileNetV2\n",
    "img_height = img_width = 128\n",
    "\n",
    "# Ładowanie MobileNetV2 bez górnej warstwy (top)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Zamrożenie wagi przetrenowanego modelu\n",
    "base_model.trainable = False\n",
    "\n",
    "# Dodanie warstw na wierzchu\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# To jest tylko przykład, można tutaj dostosować liczbę neuronów i warstw\n",
    "output = Dense(1, activation='sigmoid')(x)  # Przykładowa warstwa wyjściowa dla klasyfikacji binarnej\n",
    "\n",
    "# Skompletowanie nowego modelu\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Kompilacja modelu z niestandardową funkcją straty i optymalizatorem\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=lambda y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty=0.7), metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0514 - accuracy: 0.9861\n",
      "Test Loss: 0.051388517022132874, Test Accuracy: 0.9861111044883728\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magisterka",
   "language": "python",
   "name": "magisterka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
