{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install focal-loss\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, Input, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# glowny folder\n",
    "base_dir = '/Users/milenabiernacka/Desktop/studia/DS/semestr2/PD-magisterka/Mushroom_dataset/cnn/'\n",
    "# polaczenie glownego folderu i podfolderow z edible i poisonous\n",
    "\n",
    "edible_dir = os.path.join(base_dir, 'Edible')\n",
    "poisonous_dir = os.path.join(base_dir, 'Poisonous')\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Assuming base_dir is the path to the dataset directory\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=1,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(150, 150, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Use linear activation for Hinge loss\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seesaw_loss_with_penalty(y_true, y_pred, penalty=0.5):\n",
    "    \"\"\"\n",
    "    A simplified conceptual version of seesaw loss for binary classification.\n",
    "    This function penalizes the loss for the majority class and reduces the penalty\n",
    "    for the minority class, attempting to balance the seesaw between classes.\n",
    "\n",
    "    Args:\n",
    "    - y_true: True labels.\n",
    "    - y_pred: Predicted labels.\n",
    "    - penalty: The penalty factor for the majority class. Lower values reduce the loss\n",
    "               contribution from the majority class.\n",
    "\n",
    "    Returns:\n",
    "    - A modified binary cross-entropy loss that incorporates class balancing.\n",
    "    \"\"\"\n",
    "    # Standard binary cross-entropy\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    # Determine weights for each sample based on its true label\n",
    "    weights = K.abs(y_true - penalty)  # Reduce weight for majority class (assumed to be 1)\n",
    "\n",
    "    # Apply seesaw penalty\n",
    "    weighted_bce = weights * bce\n",
    "\n",
    "    return K.mean(weighted_bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=lambda y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty=0.8), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1399/1399 [==============================] - 57s 40ms/step - loss: 0.1770 - accuracy: 0.7362 - val_loss: 0.1479 - val_accuracy: 0.7326\n",
      "Epoch 2/20\n",
      "1399/1399 [==============================] - 53s 38ms/step - loss: 0.1392 - accuracy: 0.7412 - val_loss: 0.1297 - val_accuracy: 0.7431\n",
      "Epoch 3/20\n",
      "1399/1399 [==============================] - 57s 40ms/step - loss: 0.1188 - accuracy: 0.7777 - val_loss: 0.1182 - val_accuracy: 0.7569\n",
      "Epoch 4/20\n",
      "1399/1399 [==============================] - 60s 43ms/step - loss: 0.0982 - accuracy: 0.8392 - val_loss: 0.0760 - val_accuracy: 0.9132\n",
      "Epoch 5/20\n",
      "1399/1399 [==============================] - 58s 41ms/step - loss: 0.0831 - accuracy: 0.8721 - val_loss: 0.0654 - val_accuracy: 0.8993\n",
      "Epoch 6/20\n",
      "1399/1399 [==============================] - 59s 42ms/step - loss: 0.0696 - accuracy: 0.9021 - val_loss: 0.0557 - val_accuracy: 0.9306\n",
      "Epoch 7/20\n",
      "1399/1399 [==============================] - 61s 43ms/step - loss: 0.0637 - accuracy: 0.9056 - val_loss: 0.0447 - val_accuracy: 0.9410\n",
      "Epoch 8/20\n",
      "1399/1399 [==============================] - 60s 43ms/step - loss: 0.0564 - accuracy: 0.9157 - val_loss: 0.0718 - val_accuracy: 0.9479\n",
      "Epoch 9/20\n",
      "1399/1399 [==============================] - 60s 43ms/step - loss: 0.0488 - accuracy: 0.9271 - val_loss: 0.0321 - val_accuracy: 0.9514\n",
      "Epoch 10/20\n",
      "1399/1399 [==============================] - 60s 43ms/step - loss: 0.0404 - accuracy: 0.9450 - val_loss: 0.1228 - val_accuracy: 0.9306\n",
      "Epoch 11/20\n",
      "1399/1399 [==============================] - 59s 42ms/step - loss: 0.0318 - accuracy: 0.9550 - val_loss: 0.0259 - val_accuracy: 0.9757\n",
      "Epoch 12/20\n",
      "1399/1399 [==============================] - 58s 42ms/step - loss: 0.0345 - accuracy: 0.9578 - val_loss: 0.0397 - val_accuracy: 0.9375\n",
      "Epoch 13/20\n",
      "1399/1399 [==============================] - 59s 42ms/step - loss: 0.0314 - accuracy: 0.9607 - val_loss: 0.0179 - val_accuracy: 0.9653\n",
      "Epoch 14/20\n",
      "1399/1399 [==============================] - 61s 43ms/step - loss: 0.0276 - accuracy: 0.9721 - val_loss: 0.0208 - val_accuracy: 0.9583\n",
      "Epoch 15/20\n",
      "1399/1399 [==============================] - 61s 43ms/step - loss: 0.0240 - accuracy: 0.9671 - val_loss: 0.0386 - val_accuracy: 0.9514\n",
      "Epoch 16/20\n",
      "1399/1399 [==============================] - 61s 44ms/step - loss: 0.0201 - accuracy: 0.9685 - val_loss: 0.0435 - val_accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "1399/1399 [==============================] - 62s 44ms/step - loss: 0.0172 - accuracy: 0.9764 - val_loss: 0.0254 - val_accuracy: 0.9583\n",
      "Epoch 18/20\n",
      "1399/1399 [==============================] - 61s 43ms/step - loss: 0.0204 - accuracy: 0.9700 - val_loss: 0.1676 - val_accuracy: 0.9167\n",
      "Epoch 19/20\n",
      "1399/1399 [==============================] - 59s 43ms/step - loss: 0.0252 - accuracy: 0.9707 - val_loss: 0.0138 - val_accuracy: 0.9826\n",
      "Epoch 20/20\n",
      "1399/1399 [==============================] - 64s 46ms/step - loss: 0.0105 - accuracy: 0.9878 - val_loss: 0.0199 - val_accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 127s 16s/step - loss: 0.0198 - accuracy: 0.9792\n",
      "Test Loss: 0.01980467326939106, Test Accuracy: 0.9791666865348816\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=Adam(learning_rate=1e-4), loss=lambda y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty=0.5), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "#     epochs=20,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "# print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=1,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1399/1399 [==============================] - 21s 14ms/step - loss: 0.0558 - accuracy: 0.9214 - val_loss: 0.0180 - val_accuracy: 0.9722\n",
      "Epoch 2/20\n",
      "1399/1399 [==============================] - 16s 11ms/step - loss: 0.0252 - accuracy: 0.9671 - val_loss: 0.0158 - val_accuracy: 0.9896\n",
      "Epoch 3/20\n",
      "1399/1399 [==============================] - 15s 11ms/step - loss: 0.0166 - accuracy: 0.9793 - val_loss: 0.0172 - val_accuracy: 0.9896\n",
      "Epoch 4/20\n",
      "1399/1399 [==============================] - 16s 12ms/step - loss: 0.0095 - accuracy: 0.9878 - val_loss: 0.0148 - val_accuracy: 0.9931\n",
      "Epoch 5/20\n",
      "1399/1399 [==============================] - 18s 13ms/step - loss: 0.0145 - accuracy: 0.9836 - val_loss: 0.0112 - val_accuracy: 0.9757\n",
      "Epoch 6/20\n",
      "1399/1399 [==============================] - 19s 14ms/step - loss: 0.0169 - accuracy: 0.9814 - val_loss: 0.0082 - val_accuracy: 0.9931\n",
      "Epoch 7/20\n",
      "1399/1399 [==============================] - 19s 13ms/step - loss: 0.0120 - accuracy: 0.9857 - val_loss: 0.0087 - val_accuracy: 0.9931\n",
      "Epoch 8/20\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0051 - accuracy: 0.9936 - val_loss: 0.0034 - val_accuracy: 0.9965\n",
      "Epoch 9/20\n",
      "1399/1399 [==============================] - 23s 16ms/step - loss: 0.0060 - accuracy: 0.9929 - val_loss: 0.0049 - val_accuracy: 0.9931\n",
      "Epoch 10/20\n",
      "1399/1399 [==============================] - 19s 13ms/step - loss: 0.0058 - accuracy: 0.9929 - val_loss: 0.0101 - val_accuracy: 0.9896\n",
      "Epoch 11/20\n",
      "1399/1399 [==============================] - 24s 17ms/step - loss: 0.0202 - accuracy: 0.9814 - val_loss: 0.0118 - val_accuracy: 0.9931\n",
      "Epoch 12/20\n",
      "1399/1399 [==============================] - 21s 15ms/step - loss: 0.0102 - accuracy: 0.9878 - val_loss: 0.0098 - val_accuracy: 0.9861\n",
      "Epoch 13/20\n",
      "1399/1399 [==============================] - 19s 14ms/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 0.0038 - val_accuracy: 0.9931\n",
      "Epoch 14/20\n",
      "1399/1399 [==============================] - 20s 15ms/step - loss: 0.0042 - accuracy: 0.9964 - val_loss: 0.0064 - val_accuracy: 0.9931\n",
      "Epoch 15/20\n",
      "1399/1399 [==============================] - 22s 16ms/step - loss: 0.0036 - accuracy: 0.9964 - val_loss: 0.0065 - val_accuracy: 0.9931\n",
      "Epoch 16/20\n",
      "1399/1399 [==============================] - 22s 16ms/step - loss: 0.0060 - accuracy: 0.9950 - val_loss: 0.0096 - val_accuracy: 0.9896\n",
      "Epoch 17/20\n",
      "1399/1399 [==============================] - 22s 16ms/step - loss: 0.0011 - accuracy: 0.9979 - val_loss: 0.0278 - val_accuracy: 0.9792\n",
      "Epoch 18/20\n",
      "1399/1399 [==============================] - 23s 16ms/step - loss: 0.0072 - accuracy: 0.9914 - val_loss: 0.0102 - val_accuracy: 0.9896\n",
      "Epoch 19/20\n",
      "1399/1399 [==============================] - 22s 16ms/step - loss: 0.0011 - accuracy: 0.9986 - val_loss: 0.0594 - val_accuracy: 0.9757\n",
      "Epoch 20/20\n",
      "1399/1399 [==============================] - 23s 16ms/step - loss: 0.0108 - accuracy: 0.9921 - val_loss: 0.0059 - val_accuracy: 0.9965\n"
     ]
    }
   ],
   "source": [
    "# Wykorzystanie pretrenowanych sieci\n",
    "### MobileNetV2\n",
    "img_height = img_width = 128\n",
    "\n",
    "# Ładowanie MobileNetV2 bez górnej warstwy (top)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Zamrożenie wagi przetrenowanego modelu\n",
    "base_model.trainable = False\n",
    "\n",
    "# Dodanie warstw na wierzchu\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# To jest tylko przykład, można tutaj dostosować liczbę neuronów i warstw\n",
    "output = Dense(1, activation='sigmoid')(x)  # Przykładowa warstwa wyjściowa dla klasyfikacji binarnej\n",
    "\n",
    "# Skompletowanie nowego modelu\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Kompilacja modelu z niestandardową funkcją straty i optymalizatorem\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=lambda y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty=0.8), metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 96ms/step - loss: 0.0301 - accuracy: 0.9826\n",
      "Test Loss: 0.030124111101031303, Test Accuracy: 0.9826388955116272\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magisterka",
   "language": "python",
   "name": "magisterka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
