{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install focal-loss\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, Input, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# glowny folder\n",
    "base_dir = '/Users/milenabiernacka/Desktop/studia/DS/semestr2/PD-magisterka/Mushroom_dataset/cnn/'\n",
    "# polaczenie glownego folderu i podfolderow z edible i poisonous\n",
    "\n",
    "edible_dir = os.path.join(base_dir, 'Edible')\n",
    "poisonous_dir = os.path.join(base_dir, 'Poisonous')\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Assuming base_dir is the path to the dataset directory\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=1,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(150, 150, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Use linear activation for Hinge loss\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seesaw_loss_with_penalty(y_true, y_pred, penalty=0.5):\n",
    "    \"\"\"\n",
    "    A simplified conceptual version of seesaw loss for binary classification.\n",
    "    This function penalizes the loss for the majority class and reduces the penalty\n",
    "    for the minority class, attempting to balance the seesaw between classes.\n",
    "\n",
    "    Args:\n",
    "    - y_true: True labels.\n",
    "    - y_pred: Predicted labels.\n",
    "    - penalty: The penalty factor for the majority class. Lower values reduce the loss\n",
    "               contribution from the majority class.\n",
    "\n",
    "    Returns:\n",
    "    - A modified binary cross-entropy loss that incorporates class balancing.\n",
    "    \"\"\"\n",
    "    # Standard binary cross-entropy\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    # Determine weights for each sample based on its true label\n",
    "    weights = K.abs(y_true - penalty)  # Reduce weight for majority class (assumed to be 1)\n",
    "\n",
    "    # Apply seesaw penalty\n",
    "    weighted_bce = weights * bce\n",
    "\n",
    "    return K.mean(weighted_bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=lambda y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty=0.8), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87/87 [==============================] - 32s 357ms/step - loss: 0.1910 - accuracy: 0.7317 - val_loss: 0.1604 - val_accuracy: 0.7431\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 29s 331ms/step - loss: 0.1549 - accuracy: 0.7375 - val_loss: 0.1550 - val_accuracy: 0.7361\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 30s 346ms/step - loss: 0.1417 - accuracy: 0.7375 - val_loss: 0.1578 - val_accuracy: 0.7326\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 29s 336ms/step - loss: 0.1320 - accuracy: 0.7513 - val_loss: 0.1181 - val_accuracy: 0.7604\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 29s 333ms/step - loss: 0.1196 - accuracy: 0.7614 - val_loss: 0.1129 - val_accuracy: 0.7986\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 29s 333ms/step - loss: 0.1110 - accuracy: 0.7773 - val_loss: 0.0940 - val_accuracy: 0.8264\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 30s 341ms/step - loss: 0.1050 - accuracy: 0.8200 - val_loss: 0.0905 - val_accuracy: 0.8194\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 34s 390ms/step - loss: 0.0944 - accuracy: 0.8330 - val_loss: 0.0835 - val_accuracy: 0.8403\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 30s 347ms/step - loss: 0.0881 - accuracy: 0.8518 - val_loss: 0.0700 - val_accuracy: 0.8785\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 21s 242ms/step - loss: 0.0793 - accuracy: 0.8626 - val_loss: 0.0652 - val_accuracy: 0.8958\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 16s 188ms/step - loss: 0.0755 - accuracy: 0.8814 - val_loss: 0.0668 - val_accuracy: 0.8646\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 17s 199ms/step - loss: 0.0661 - accuracy: 0.8988 - val_loss: 0.0579 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 17s 195ms/step - loss: 0.0702 - accuracy: 0.8966 - val_loss: 0.0698 - val_accuracy: 0.8299\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 16s 185ms/step - loss: 0.0649 - accuracy: 0.9002 - val_loss: 0.0507 - val_accuracy: 0.9097\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 17s 191ms/step - loss: 0.0547 - accuracy: 0.9203 - val_loss: 0.0457 - val_accuracy: 0.9236\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 18s 201ms/step - loss: 0.0565 - accuracy: 0.9197 - val_loss: 0.0400 - val_accuracy: 0.9271\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 17s 192ms/step - loss: 0.0472 - accuracy: 0.9299 - val_loss: 0.0343 - val_accuracy: 0.9479\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 17s 199ms/step - loss: 0.0494 - accuracy: 0.9306 - val_loss: 0.0367 - val_accuracy: 0.9514\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 29s 339ms/step - loss: 0.0486 - accuracy: 0.9335 - val_loss: 0.0387 - val_accuracy: 0.9201\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 33s 373ms/step - loss: 0.0455 - accuracy: 0.9328 - val_loss: 0.0360 - val_accuracy: 0.9514\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 97ms/step - loss: 0.0382 - accuracy: 0.9514\n",
      "Test Loss: 0.03823953494429588, Test Accuracy: 0.9513888955116272\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=lambda y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty=0.5), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1399/1399 [==============================] - 12s 8ms/step - loss: 0.0685 - accuracy: 0.9135 - val_loss: 0.0791 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "1399/1399 [==============================] - 14s 10ms/step - loss: 0.0242 - accuracy: 0.9643 - val_loss: 0.0190 - val_accuracy: 0.9653\n",
      "Epoch 3/20\n",
      "1399/1399 [==============================] - 14s 10ms/step - loss: 0.0128 - accuracy: 0.9843 - val_loss: 0.0121 - val_accuracy: 0.9792\n",
      "Epoch 4/20\n",
      "1399/1399 [==============================] - 15s 11ms/step - loss: 0.0099 - accuracy: 0.9878 - val_loss: 0.0210 - val_accuracy: 0.9826\n",
      "Epoch 5/20\n",
      "1399/1399 [==============================] - 15s 11ms/step - loss: 0.0150 - accuracy: 0.9800 - val_loss: 0.0095 - val_accuracy: 0.9896\n",
      "Epoch 6/20\n",
      "1399/1399 [==============================] - 16s 11ms/step - loss: 0.0120 - accuracy: 0.9900 - val_loss: 0.0104 - val_accuracy: 0.9861\n",
      "Epoch 7/20\n",
      "1399/1399 [==============================] - 16s 11ms/step - loss: 0.0125 - accuracy: 0.9843 - val_loss: 0.0054 - val_accuracy: 0.9931\n",
      "Epoch 8/20\n",
      "1399/1399 [==============================] - 17s 12ms/step - loss: 0.0092 - accuracy: 0.9864 - val_loss: 0.0435 - val_accuracy: 0.9792\n",
      "Epoch 9/20\n",
      "1399/1399 [==============================] - 15s 10ms/step - loss: 0.0058 - accuracy: 0.9936 - val_loss: 0.0062 - val_accuracy: 0.9896\n",
      "Epoch 10/20\n",
      "1399/1399 [==============================] - 14s 10ms/step - loss: 0.0045 - accuracy: 0.9950 - val_loss: 0.0201 - val_accuracy: 0.9931\n",
      "Epoch 11/20\n",
      "1399/1399 [==============================] - 14s 10ms/step - loss: 0.0065 - accuracy: 0.9929 - val_loss: 0.0737 - val_accuracy: 0.9236\n",
      "Epoch 12/20\n",
      "1399/1399 [==============================] - 16s 11ms/step - loss: 0.0110 - accuracy: 0.9871 - val_loss: 0.0108 - val_accuracy: 0.9931\n",
      "Epoch 13/20\n",
      "1399/1399 [==============================] - 16s 12ms/step - loss: 0.0080 - accuracy: 0.9914 - val_loss: 0.0231 - val_accuracy: 0.9757\n",
      "Epoch 14/20\n",
      "1399/1399 [==============================] - 18s 13ms/step - loss: 0.0067 - accuracy: 0.9950 - val_loss: 0.0170 - val_accuracy: 0.9861\n",
      "Epoch 15/20\n",
      "1399/1399 [==============================] - 18s 13ms/step - loss: 0.0054 - accuracy: 0.9936 - val_loss: 0.0236 - val_accuracy: 0.9896\n",
      "Epoch 16/20\n",
      "1399/1399 [==============================] - 20s 14ms/step - loss: 0.0101 - accuracy: 0.9893 - val_loss: 0.0133 - val_accuracy: 0.9896\n",
      "Epoch 17/20\n",
      " 138/1399 [=>............................] - ETA: 20s - loss: 6.4718e-05 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# Wykorzystanie pretrenowanych sieci\n",
    "### MobileNetV2\n",
    "img_height = img_width = 128\n",
    "\n",
    "# Ładowanie MobileNetV2 bez górnej warstwy (top)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Zamrożenie wagi przetrenowanego modelu\n",
    "base_model.trainable = False\n",
    "\n",
    "# Dodanie warstw na wierzchu\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# To jest tylko przykład, można tutaj dostosować liczbę neuronów i warstw\n",
    "output = Dense(1, activation='sigmoid')(x)  # Przykładowa warstwa wyjściowa dla klasyfikacji binarnej\n",
    "\n",
    "# Skompletowanie nowego modelu\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Kompilacja modelu z niestandardową funkcją straty i optymalizatorem\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=lambda y_true, y_pred: seesaw_loss_with_penalty(y_true, y_pred, penalty=0.8), metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magisterka",
   "language": "python",
   "name": "magisterka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
